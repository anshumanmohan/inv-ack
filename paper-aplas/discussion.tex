\newcommand{\ackt}{\ensuremath{\underline{\alpha}}}

\subsection{Two-parameter inverse Ackermann function}
Some authors~\cite{chazelle,tarjan} prefer a two-parameter inverse Ackermann function.
\begin{defn} \label{defn: 2para-alpha}
	The two-parameter inverse Ackermann function is defined as:
	\begin{equation} \label{eq: tmp-2para-alpha}
	\ackt (m, n) \triangleq \min\left\{i \ge 1 : \Ack\left(i, \left\lfloor \frac{m}{n} \right\rfloor \right)\ge \log_2n \right\}
	\end{equation}
\end{defn}
Note that $\ackt(n, n)$ and the single-parameter $\alpha(n)$ 
are neither equal nor directly related, but
it is straightforward to modify our techniques to compute $\ackt(m, n)$.
\hide{This function arises from deep runtime analysis of the disjoint-set data structure. Tarjan \cite{tarjan} showed that, in the disjoint-set data structure, the time required $t(m,n)$ for a sequence of $m$ \textsc{\color{magenta}FIND}s intermixed with $n-1$ \textsc{\color{magenta}UNION}s (such that $m \geq n$) is bounded as: $k_{1}m\cdot\alpha(m,n) \leq t(m,n) \leq k_{2}m\cdot\alpha(m,n)$. In graph theory, Chazelle \cite{chazelle} showed that the minimum spanning tree of a connected graph with $n$ vertices and $m$ edges can be found in time $O(m\cdot\alpha(m,n))$. Computing this function is in fact easier than $\alpha(n)$, as when $m$ and $n$ are given, we are reduced to finding the minimum $i\ge 1$ such that $\Ack_i(s)\ge t$ for $s, t$ fixed, which can be done with the following variant of the \emph{inverse Ackermann worker}.
}
\begin{defn} \label{defn: 2para-inv-ack-worker}
	The two-parameter inverse Ackermann worker is a function $\ackt^{\W}$: 
	\hide{$(\mathbb{N}\to \mathbb{N}) \times \mathbb{N}^3\to \mathbb{N}$ such that for all $n, k, b\in \mathbb{N}$ and $f:\mathbb{N}\to \mathbb{N}$:}
	\begin{equation} \label{eq: 2para-inv-ack-worker-recursion}
	\ackt^{\W}(f, n, k, b) = \begin{cases}
	0 & \text{if } b = 0 \vee n\le k \\ 1 + \ackt^{\W}\big(\cdt{f}{1}\circ f , \cdt{f}{1}(n), k, b-1\big) & \text{if } b \ge 1 \wedge n \ge k+1
	\end{cases}
	\end{equation}
\end{defn}
%Similar to the one-parameter version, the following theorem establishes the correct setting for $\W\alpha_2$ to compute $\alpha(m, n)$.
\begin{thm}
	$\displaystyle \ackt(m, n) = 1 + \ackt^{\W}\left(\alpha_1, \alpha_1\big(\lceil\log_2n \rceil\big), \left\lfloor \frac{m}{n} \right\rfloor, \lceil\log_2n \rceil \right)$.
\end{thm}
\hide{
	\begin{proof}[Proof Sketch]
	 It is easy to prove in a similar fashion to \cref{lem: inv-ack-worker-intermediate} that for all $n, b, k$ and $i$, if $\alpha_i(n) > k$ and $b > i$, then
	\begin{equation*}
	\W\alpha_2\big(\alpha_1, \alpha_1(b), k, b\big) = i + \W\alpha_2\big(\alpha_{i+1}, \alpha_{i+1}(n), k, b - i\big)
	\end{equation*}
	Now let $k \triangleq \lfloor m/n \rfloor$, $b \triangleq \lceil \log_2n \rceil$ and $l \triangleq \min\big\{i : \alpha_i(b)\le k\big\}$, which exists because $\Ack(i, \cdot)$ increases strictly with $i$. Then $\alpha(m, n) = \max{1, l}$. If $l = 0$, $\alpha_1(b) \le \alpha_0(b) \le k$, so $\W\alpha_2\big(\alpha_1, \alpha_1(b), k, b\big) = 0$, as desired. If $l \ge 1$,
	\begin{equation*}
	1 + \W\alpha_2\big(\alpha_1, \alpha_1(b), k, b\big)
	= 1 + l - 1 + \W\alpha_2\big(\alpha_l, \alpha_l(b), k, b-l\big) = l
	\end{equation*}
	Here $b\ge l$ due to the fact that $\Ack(b, k)\ge b$, so $\alpha_b(b)\le k$. This completes the proof.
\end{proof}}%end hide

\hide{
\subsection{Lower inverse of hyperoperations and Ackermann function}
{\color{red}TODO. I'm not sure if I have time to write about this one.}
}


\subsection{A performance improvement with binary numbers}
Thus far we have used the Coq type \li{nat}, which is a unary system of 
natural numbers no more sophisticated than tally marks: 
a number~$n$ is represented in~$n$ bits. 
The binary system represents numbers using $0$s and $1$s, thus 
allowing~$n$ to be represented in $\lfloor \log_{2} n \rfloor + 1$ bits.
In both systems, addition and subtraction of two $n$-bit numbers take $\Theta(n)$ time, 
while multiplication takes $\Theta \big(n^2\big)$ time. 
The binary system thus easily outperforms the unary in basic arithmetic operations. 

Here we show that this advantage carries forward to the computation of 
hyperoperations, Ackermann functions, and their inverses. 
Coq has support for binary numbers with the type \li{N}, which consists 
of constructors \li{0} and \li{positive}:
\begin{lstlisting}
Inductive positive : Set := 
  | xI : positive -> positive | xO : positive -> positive
  | xH : positive.
\end{lstlisting}
Constructor \li{xH} represents $1$, and constructors \li{xO} and \li{xI} represent 
appending $0$ and $1$ respectively. 
By always starting with $1$, \li{positive} dodges
the issue of disambiguating \emph{e.g.} the numbers \li{011} and 
\li{00011}, which represent the same number but pose
a minor technical challenge. 
To represent $0$, the type \li{N} simply provides a separate constructor \li{0}. 

%\paragraph*{Exponentiation with Binary Numbers}
%This a massive improvement over the bound $\Theta\left(a^b\right)$ of exponentiation in the unary system.


\hide{
\begin{lstlisting}
Definition exp (x y : N) : N := match y with
| 0 => 1 | Npos y'
  => match x with
     | 0 => 0 | _ => 
     let fix expPos (p : positive) :=
            match p with
            | xH => x
            | xI p' => let t := expPos p' in x * t * t
            | xO p' => let t := expPos p' in t * t
            end in expPos y'
     end end.
\end{lstlisting}
To analyse the performance of this definition, let us denote the computation time for \li{exp a b} and \li{a * b} respectively by $\Texp (a, b)$ and $ \Tmul (a, b)$.Now
\begin{equation*}
\begin{aligned}
\Texp(a, b)
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right)
+ \Tmul\left(a^{\left\lfloor \frac{b}{2} \right\rfloor}, a^{\left\lfloor \frac{b}{2} \right\rfloor} \right) + \Tmul\left(a^{2\left\lfloor \frac{b}{2} \right\rfloor}, a\right) \\
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right) + \left\lfloor \frac{b}{2} \right\rfloor^2 \big(\log_2 a + 1\big)^2 + 2\left\lfloor \frac{b}{2} \right\rfloor \big(\log_2 a + 1\big)^2 \\
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right) + 3\left(\frac{b}{2}\right)^2 \big(\log_2 a + 1\big)^2
\end{aligned}
\end{equation*}
Thus, $\Texp(a, b) \le 3\big(\log_2 a + 1\big)^2 \sum_{k=1}^{\infty} \frac{b^{2k}}{4^k} = \bigO\left(b^2\big(\log_2 a + 1\big)^2\right)$. 
This a massive improvement over the bound $\Theta\left(a^b\right)$ of exponentiation in the unary system.
} % end hide

\paragraph*{Countdown and Contractions with Binary Numbers}
\hide{Apart from speeding up addition and multiplication, the binary system does the same for their successor, namely exponentiation. We achieve this by \emph{repeated squaring},
which by standard techniques allows us to calculate $a^b$ in $\bigO\left(b^2\big(\log_2 a + 1\big)^2\right)$.} % end hide

Although the definition of \emph{countdown} is independent of the system representing natural numbers, its Coq definition should be adjusted appropriately to account for the type \li{N}. The first step is to translate the arguments of \emph{countdown worker} from \li{nat} to \li{N}. While the type of the budget \li{k} should remain \li{nat} as it must decrease by $1$ on every recursive step, all other \li{nat} arguments should be changed to \li{N}, and functions on \li{nat} to functions on \li{N}.
\begin{lstlisting}
Fixpoint bin_countdown_worker (f : N -> N) (a n : N) (b : nat) : N :=
  match b with
  | O    => 0
  | S b' => if (n <=? a) then 0
             else 1 + bin_countdown_worker f a (f n) b'
end.
\end{lstlisting}
Determining the appropriate budget value for \emph{countdown} is trickier. 
The naÃ¯ve approach is to simply use the \li{nat} translation of \li{n}, 
\emph{i.e.} \li{N.to_nat n}. However, the conversion to \li{nat} alone 
takes linear time in \li{n}, or exponential in its length of representation, 
which is obviously untenable as we try to leverage binary numbers 
to improve efficiency. 
Unfortunately, a linear-sized budget is necessary to compute countdowns of functions like $\lambda n.(n-2)$, which is among both inverse hyperoperations and inverse Ackermann hierarchies.

The key is to ignore these functions entirely and focus on functions that can bring their argument to below any threshold with repeated applications in logarithm time, which allows a logarithm-sized budget for countdown worker. The following concept aims to describe a type of \emph{fast-contracting} functions.
\begin{defn} \label{defn: bin-contraction}
	A contraction $f$ is \emph{binary strict above} $a\in \mathbb{N}$ if $f(n) \le \lfloor \frac{n + a}{2} \rfloor$ for all $n > a$.
\end{defn}
The key advantage of binary strict contractions is that if a contraction $f$ is binary strict above some $a$, then for all $n > a$ and $k$,
\begin{equation*}
f(n) \le \left\lfloor \frac{n - a}{2^k} \right\rfloor + a
\end{equation*}
Therefore within $\lfloor \log_2 (n - a) \rfloor + 1$ compositional applications of $f$, any input $n$ will go below $a$, so we can choose this number as the budget for \emph{countdown worker} to successfully count the correct countdown value. Our last step is to compute this budget as a \li{nat} given the number $n$ of type \li{N}, which is done with the following function:

\begin{lstlisting}
Definition nat_size (n : N) : nat :=
  match n with
  | 0 => 0%nat
  | Npos p => let fix nat_pos_size (x : positive) : nat :=
                  match x with
                  | xH => 1%nat
                  | xI y | xO y => S (nat_pos_size y) 
                  end
              in nat_pos_size p
  end.
\end{lstlisting}
Note that \li{nat_size} outputs $0$ on $0$, and on any positive number $m$ the size of its binary representation, thus equals to $\lfloor \log_{2} m \rfloor + 1$. To sum up, we have the following Coq definition of countdown on \li{N}.

\begin{lstlisting}
Definition bin_countdown (f : N -> N) (a n : N) : N := 
  bin_countdown_worker f a n (nat_size (n - a)).
\end{lstlisting}

\paragraph*{Time complexity of countdown on strict binary contractions.}

On strict binary contractions, the binary version of countdown does exactly the same computations as the original one on \li{nat}, thus its computation time structure is the same. The only difference is the computation time of each component in the sum. We examine a more detailed breakdown of the time components below.
\begin{equation} \label{eq: cdt-bin-runtime-struct}
	\runtime_{\cdt{f}{a}}(n) =
\hspace{5pt}
\begin{aligned} 
& \textstyle \sum_{i=0}^{\cdt{f}{a}(n) - 1} \runtime_f\left(f^{(i)}(n)\right)
&+& \textstyle ~ \sum_{i=0}^{\cdt{f}{a}(n)}\Tleb\left(f^{(i)}(n), a\right) \\
& \textstyle +~ \sum_{i=0}^{\cdt{f}{a}(n) - 1}\Tsucc(i)
&+& ~ \runtime_{\li{sub}}(n, a)
\end{aligned},
\end{equation}
where
$\Tleb(x, y)$ is the computation time for \li{x <=? y}, 
$\Tsucc(u)$ for \li{N.succ(u)}, 
$\runtime_{\li{nat_size}}(n - a)$ for \li{nat_size(n - a)}, and
$\runtime_{\li{sub}}(n, a)$ for $n - a$.

In the unary system, $\Tleb\left(f^{(i)}(n), a\right) = a + 1$ and $\Tsucc(i) = 1$, which accumulate into the summand $\Theta\big((a + 1)\cdt{f}{a}(n) \big)$ in Lemma~\ref{lem: cdt-runtime}. 

In the binary system,
$\Tleb(x, y) = \Theta\left(1 + \log_2(\min\{x, y\})\right)$ and 
$\Tsucc(u)$ is the number of consecutive least significant \li{1} bits of $u$.
Since $f^{(i)}(n)\ge a$ for $i < \cdt{f}{a}(n)$, the $\Tleb$ sum (third summand) on the RHS of~(\ref{eq: cdt-bin-runtime-struct}) is $\Theta\big((\log_2a + 1)\cdt{f}{a}(n)\big)$. The fourth and fifth summands are clearly $\Theta\left(\log_2n + 1\right)$ in total.
For the second summand, we will show that $\Tsucc(i)$ is amortized constant.
\begin{lem}
	For all $n\ge 1$, $S(n) = \displaystyle \sum_{i=0}^{n-1}\Tsucc(i) \le 2n + \log_2(n)$.
\end{lem}
\begin{proof}
	For $n = 1$, $\Tsucc(0) = 1$, our goal is $1\le 2$, which is trivial. For $n > 1$, observe that for all $k$, $\Tsucc(k) = \Tsucc\left(\frac{k-1}{2}\right) + 1$ if $k$ is odd and $1$ if $k$ is even. Thus for odd $n$, $S(n) = S(n-1) + 1$; for even $n$, i.e. $n = 2m$ for $m\ge 1$,
	\begin{equation*}
	\begin{aligned}
	S(n) & = \sum_{i=0}^{m}\Tsucc(2i) + \sum_{i=0}^{m-1}\Tsucc(2i+1)
	= \sum_{i=0}^{m}1 + \sum_{i=0}^{m-1}\left[\Tsucc(i) + 1\right] \\
	& = m+1 + S(m) + m = S(m) + n + 1
	\end{aligned}
	\end{equation*}
	From the above, it is easy to complete the proof via induction.
\end{proof}
The above analysis leads to the following result about countdown with binary numbers.
\begin{thm} \label{thm: cdt-runtime-bin}
	If $n$ is represented in binary, we have
	\begin{equation} \label{eq: cdt-runtime-bin}
	\runtime\big(\cdt{f}{a}\ , n\big) = \sum_{i=0}^{\cdt{f}{a}(n) - 1}
	\runtime\left(f, f^{(i)}(n)\right) + \Theta\big((\log_2a + 1)\cdt{f}{a}(n)\big) + \Theta\left(\log_2 n\right)
	\end{equation}
\end{thm}
%Substituting $a=1$ into \eqref{eq: cdt-runtime-bin} shows that \Cref{lem: inv-ack-hier-runtime} still holds.
%Similar to \Cref{sect: hard-code-lvl2}, the use of binaries is not immediately effective since the first level. We delve deeper into the hierarchy by \emph{hard-coding the $3^{\text{th}}$ level} and starts from there. Now
%\begin{equation*}
%\forall n, n+2  < n+3 < 2(n+2) \iff \forall n,
%\lfloor \log_2(n+2) \rfloor < \lceil \log_2(n+3) \rceil \le \lfloor \log_2(n+2) \rfloor + 1
%\end{equation*}
%This shift from floor to ceiling enables a direct computation, since $\lceil \log_2(n+3) \rceil$ can now be seen as the size of $(n+2)$'s binary representation.
%\begin{lstlisting}
%Definition alpha3 (n: N) : N := N.size (n+2) - 3.
%\end{lstlisting}
%Let $n\ge 2$. The computation of \li{N.size(n)} takes time equal to itself, so the above definition gives $\runtime(\alpha_3, n) \le 2\log_2n$. Fix an $i\ge 3$ and suppose $\runtime(\alpha_i, n) \le C_i\log_2n$. By \Cref{lem: inv-ack-hier-runtime},
\paragraph*{An inverse Ackermann computation in $\bigO\left(4^{\alpha(n)}\log_2 n\right)$ time.}
Our new Coq definition is able to compute the correct countdown value, but only for strict binary contractions. Fortunately, the inverse hyperoperations $a\angle{n}b$ are all strict binary contractions when $a\ge 2$ starting from $n = 3$, so are the inverse Ackermann hierarchy $\alpha_n$ starting from $n = 2$. We can hard-code their few initial levels. We focus on the latter in this paper, but the former's definition can also be found in our code repository.
\begin{lstlisting}
Fixpoint bin_alpha (m : nat) (x : N) : N :=
  match m with
  | 0%nat => x - 1
  | 1%nat => x - 2
  | 2%nat => N.div2 (x - 2)
  | S m'  => countdown (bin_alpha m') 1 (bin_alpha m' x)
  end.
\end{lstlisting}
The first three levels are hard-coded, as we need to start the countdown from a binary strict contraction. Note that for all $x$,
\begin{equation*}
\left\lfloor \frac{x - 2}{2} \right\rfloor = \left\lceil \frac{x - 3}{2} \right\rceil \le \min\left\{x, \frac{x + 1}{2}\right\},
\end{equation*}
so the third level is correct and also a binary strict contraction above $1$. Next, we define the \emph{inverse Ackermann worker}.
\begin{lstlisting}
Fixpoint bin_inv_ack_worker (f : N -> N) (n k : N) (bud : nat) : N :=
  match bud with
  | 0%nat  => k
  | S bud' => if n <=? k then k
              else let g := (bin_countdown f 1) in
                   bin_inv_ack_worker (compose g f) (g n) (N.succ k) bud'
  end.
\end{lstlisting}
Note that the above Coq Fixpoint is the direct translation of the \li{inv_ack_worker} on \li{nat}, with only the budget remaining \li{nat} as it is the decreasing argument. Now the inverse Ackermann function can be computed by the following Coq definition:
\begin{lstlisting}
Definition bin_inv_ack (n : N) : N :=
       if (n <=? 1) then 0
  else if (n <=? 3) then 1
  else let f := (bin_alpha 2) in
       bin_inv_ack_worker f (f n) 2 (nat_size n).
\end{lstlisting}
Similar to the inverse Ackermann hierarchy, we hard code the result for $n = 0,1,2,3$. This ensures the correct output for small $n$, while for larger $n$ we can use \li{inv_ack_worker} with $\alpha_2$, which is the first binary strictly contractive level, as the starting function. Here the budget is \li{nat_size n}, or $\lfloor \log_2n \rfloor + 1$, which is enough for $n\ge 4$. The full proof of correctness can be found in our Github repository.

To analyze the time complexity of \li{inv_ack}, we decompose it into components, in a similar fashion to the derivation of~(\ref{eq: inv-ack-runtime-improved}). We consider only $n\ge 4$.
\begin{equation*}
\runtime\left(\alpha, n\right) =
\left(\begin{aligned}
\sum_{k = 2}^{\alpha(n) - 1} \runtime\left(\cdt{\alpha_k}{1}, \alpha_k(n)\right) + \sum_{k = 2}^{\alpha(n)}\Tleb\left(\alpha_k(n), k\right) +
\sum_{k=2}^{\alpha(n) - 1}\Tsucc(k)\\
+ \runtime\left(\alpha_2, n\right) + \runtime_{\li{nat_size}}(n)
+ \Tleb(n, 1) + \Tleb(n, 3)
\end{aligned}\right)
\end{equation*}
In the above sum:
\begin{itemize}
	\item The last four summands amount up to $\Theta(\log_2n)$.
	\item The third summand is $\Theta(\alpha(n))$ since $\Tsucc$ takes amortized constant time.
	\item Each $\Tleb$ in the second summand is $\bigO\left(\log_2k\right)$, so the total sum is $\bigO\big(\alpha(n)\log_2\alpha(n)\big)$.
	\item In the first summand, for each $k$, $\runtime\left(\cdt{\alpha_k}{1}, \alpha_k(n)\right) = \runtime\left(\alpha_{k+1}, n\right) - \runtime\left(\alpha_k, n\right)$.
\end{itemize}
Therefore,
\begin{equation*}
\runtime\left(\alpha, n\right) =
\sum_{k = 2}^{\alpha(n) - 1} \big(\runtime\left(\alpha_{k+1}, n\right) - \runtime\left(\alpha_k, n\right)\big)
+ \Theta\left(\log_2 n\right) =
\runtime\left(\alpha_{\alpha(n)}, n\right) + \Theta\left(\log_2 n\right)
\end{equation*}
We bound the RHS by bounding $\runtime\left(\alpha_{\alpha(n)}(n)\right)$, and $\runtime\left(\alpha_i(n)\right)$ in general. Note that by $\alpha_2(n) = \left\lfloor \frac{n - 2}{2} \right\rfloor$, we have $\runtime(\alpha_2, n) \le 2\log_2 n$ for all $n$.

Suppose for $i\ge 2$ we already have $\runtime\left(\alpha_i(n)\right) \le C_i\log_2n$ for all $n$, and suppose all constants in asymptotic bounds in Theorem~\ref{thm: cdt-runtime-bin} are $1$, by the fact $\alpha_{i+1} = \cdt{\alpha_i}{1} \circ \alpha_i$, we have
\begin{equation*}
\begin{aligned}
& \runtime\big(\alpha_{i+1}, n\big) =
\sum_{k=1}^{\alpha_{i+1}(n)} \runtime\left(\alpha_i, \alpha_i^{(k)}(n)\right)
+ \cdt{\alpha_i}{1}\big(\alpha_i(n)\big) + \runtime\left(\alpha_i, n\right) + \log_2 n
\\
& = \sum_{k=0}^{\alpha_{i+1}(n)} \runtime\left(\alpha_i, \alpha_i^{(k)}(n)\right) + \alpha_{i+1}(n) + \log_2 n \le C_i\sum_{k=0}^{\alpha_{i+1}(n)}\log_2 \left(\alpha_i^{(k)}(n)\right) + \alpha_{i+1}(n) + \log_2 n\\
 & \le C_i\log_2n + C_i\sum_{k=1}^{\alpha_{i+1}(n)}\alpha_i^{(k)}(n) + \alpha_{i+1}(n)
 + \log_2 n \le (4C_i+2)\log_2n,
\end{aligned}
\end{equation*}
where the last inequality follows from $\alpha_{i+1}(n)\le \log_2n$ and Lemma~\ref{lem: sum-alpha-repeat}.

Picking $C_i = 4^{i-1} - 1$ gives $C_2 > 2$ and $C_{i+1} > 4C_i + 2 \ \forall i$, so $\runtime\big(\alpha_i, n\big) \le C_i\log_2n \ \forall i\ge 3$ by induction. 
By~(\ref{eq: inv-ack-runtime-improved}), for $n > 3 = \Ack(1, 1)$, $\runtime(\alpha, n) = \runtime\big(\alpha_{\alpha(n)}, n\big) = \bigO\big(4^{\alpha(n)}\log_2n\big)$. 

Note that this bound can potentially be improved by further tightening the above inequalities. Although we do not obtain an exact asymptotic runtime similar 
to Theorem~\ref{thm: inv-ack-hier-runtime-improved}, since this bound of $4^{\alpha(n)}\log_2n$ is strictly larger than the lower bound of $\log_2n$, it is still extremely small and can be bounded by simpler expressions such as $(\log_2n)^2$.
%Our result is an improved version of the inverse Ackermann function which runs in time $\bigO\big(4^{\alpha(n)}\log_2n\big)$.
%\begin{equation*}
%\alpha(n) \triangleq \begin{cases}
%0 & \text{if } n\le 1\\ 1 & \text{if } 2\le n\le 3 \\ 2 & \text{if } 4\le n\le 7 \\
%\W\alpha\left(\alpha_3,
%\alpha_3(n), 3, n\right) & \text{if } n\ge 8
%\end{cases} \quad \text{ where } \alpha_3 \triangleq \lambda m. \big(\lfloor \log_2(m+2) \rfloor - 2\big)
%\end{equation*}

\subsection{A performance improvement with binary numbers}
Thus far we have used the Coq type \li{nat}, which is a unary system of 
natural numbers no more sophisticated than tally marks: 
a number~$n$ is represented in~$n$ bits. 
The binary system, of course, represents numbers using $0$s and $1$s, thus 
allowing~$n$ to be represented in $\lfloor \log_{2} n \rfloor + 1$ bits.
In both systems, addition and subtraction of two $n$-bit numbers takes $\Theta(n)$ time, 
while multiplication takes $\Theta \big(n^2\big)$ time. 
The binary system thus easily outperforms its counterpart in basic arithmetic operations. 

Here we show that this advantage carries forward to the computation of 
hyperoperations, Ackermann functions, and their inverses. 
Coq has support for binary numbers with the type \li{N}, which consists 
of constructors \li{0} and \li{positive}:
\begin{lstlisting}
Inductive positive : Set := 
  | xI : positive -> positive | xO : positive -> positive | xH : positive.
\end{lstlisting}
Here the value \li{xH} represents $1$, and constructors \li{xO} and \li{xI} represent 
appending $0$ and $1$ respectively, \emph{i.e.} $x\to 2x$ and $x\to 2x+1$ respectively. 
This means that \li{positive} always starts with $1$ and cannot represent ~$0$, so
the type \li{N} provides a separate constructor \li{0}. 
This treatment avoids the common issue where different representations,  
\emph{e.g.} \li{001} and \li{0001}, obviously represent the same number but pose
an annoying technical challenge. 

%\paragraph*{Exponentiation with Binary Numbers}
%This a massive improvement over the bound $\Theta\left(a^b\right)$ of exponentiation in the unary system.


\hide{
\begin{lstlisting}
Definition exp (x y : N) : N := match y with
| 0 => 1 | Npos y'
  => match x with
     | 0 => 0 | _ => 
     let fix expPos (p : positive) :=
            match p with
            | xH => x
            | xI p' => let t := expPos p' in x * t * t
            | xO p' => let t := expPos p' in t * t
            end in expPos y'
     end end.
\end{lstlisting}
To analyse the performance of this definition, let us denote the computation time for \li{exp a b} and \li{a * b} respectively by $\Texp (a, b)$ and $ \Tmul (a, b)$.Now
\begin{equation*}
\begin{aligned}
\Texp(a, b)
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right)
+ \Tmul\left(a^{\left\lfloor \frac{b}{2} \right\rfloor}, a^{\left\lfloor \frac{b}{2} \right\rfloor} \right) + \Tmul\left(a^{2\left\lfloor \frac{b}{2} \right\rfloor}, a\right) \\
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right) + \left\lfloor \frac{b}{2} \right\rfloor^2 \big(\log_2 a + 1\big)^2 + 2\left\lfloor \frac{b}{2} \right\rfloor \big(\log_2 a + 1\big)^2 \\
& \le \Texp\left(a, \left\lfloor \frac{b}{2} \right\rfloor\right) + 3\left(\frac{b}{2}\right)^2 \big(\log_2 a + 1\big)^2
\end{aligned}
\end{equation*}
Thus, $\Texp(a, b) \le 3\big(\log_2 a + 1\big)^2 \sum_{k=1}^{\infty} \frac{b^{2k}}{4^k} = \bigO\left(b^2\big(\log_2 a + 1\big)^2\right)$. 
This a massive improvement over the bound $\Theta\left(a^b\right)$ of exponentiation in the unary system.
}

\paragraph*{Countdown and Contractions with Binary Numbers}
\hide{Apart from speeding up addition and multiplication, the binary system does the same for their successor, namely exponentiation. We achieve this by \emph{repeated squaring},
which by standard techniques allows us to calculate $a^b$ in $\bigO\left(b^2\big(\log_2 a + 1\big)^2\right)$.}

Although the definition of \emph{countdown} is independent of the system representing natural numbers, its Coq definition should be adjusted appropriately to account for the type \li{N}. The first step is to translate the arguments of \emph{countdown worker} from \li{nat} to \li{N}. While the type of the budget \li{k} should remain \li{nat} as it must decrease by $1$ on every recursive step, all other \li{nat} arguments should be changed to \li{N}, and functions on \li{nat} to functions on \li{N}.
\begin{lstlisting}
Fixpoint countdown_worker (f : N -> N) (a n : N) (b : nat) : N :=
  match b with
  | O    => 0
  | S b' => if (n <=? a) then 0
             else 1 + countdown_worker f a (f n) b'
end.
\end{lstlisting}
Determining the appropriate budget value for \emph{countdown} is trickier. 
The naÃ¯ve approach is to simply use the \li{nat} translation of \li{n}, 
\emph{i.e.} \li{N.to_nat n}. However, the conversion to \li{nat} alone 
takes linear time in \li{n}, or exponential in its length of representation, 
which is obviously untenable as we try to leverage binary numbers 
to improve efficiency. 
\note[slow contracting has come out of nowhere]{Unfortunately, it is the best we can do if we 
want to compute countdowns of slow-contracting functions like $\lambda n.(n - 2)$ (which is among both inverse hyperoperations and inverse Ackermann hierarchy!).}

The key is to ignore these functions entirely and focus on functions that can bring their argument to below $1$ with compositional repetition in logarithm time. The following concept aims to describe a type of \emph{fast-contracting} functions.
\begin{defn} \label{defn: bin-contraction}
	A contraction $f$ is \emph{binary strict above} $a\in \mathbb{N}$ if $f(n) \le \lfloor \frac{n + a}{2} \rfloor$ for all $n > a$.
\end{defn}
The key advantage of binary strict contractions is that if a contraction $f$ is binary strict above some $a$, then for all $n > a$ and $k$,
\begin{equation*}
f(n) \le \left\lfloor \frac{n - a}{2^k} \right\rfloor + a
\end{equation*}
Therefore within $\lfloor \log_2 (n - a) \rfloor + 1$ compositional applications of $f$, any input $n$ will go below $a$, so we can choose this number as the budget for \emph{countdown worker} to successfully count the correct countdown value. Our last step is to compute this budget as a \li{nat} given the number $n$ of type \li{N}, which is done with the following function:

\begin{lstlisting}
Definition nat_size (n : N) : nat :=
  match n with
  | 0 => 0%nat
  | Npos p => let fix nat_pos_size (x : positive) : nat :=
                  match x with
                  | xH => 1%nat
                  | xI y | xO y => S (nat_pos_size y) 
                  end
              in nat_pos_size p
  end.
\end{lstlisting}
Note that \li{nat_size} outputs $0$ on $0$, and on any positive number $m$ the size of its binary representation, thus equals to $\lfloor \log_{2} m \rfloor + 1$. To sum up, we have the following Coq definition of countdown on \li{N}.

\begin{lstlisting}
Definition countdown (f : N -> N) (a n : N) : N := 
  countdown_worker f a n (nat_size (n - a)).
\end{lstlisting}

\paragraph*{Time complexity of countdown on strict binary contractions}

On strict binary contractions, the binary version of countdown does exactly the same computations as the original one on \li{nat}, thus its computation time structure is the same. The only difference is the computation time of each component in the sum. We examine a more detailed breakdown of the time components below.
\begin{equation} \label{eq: cdt-bin-runtime-struct}
\runtime\big(\cdt{f}{a}\ , n\big) =
\hspace{5pt} \left(\begin{aligned}
& \sum_{i=0}^{\cdt{f}{a}(n) - 1} \runtime\left(f, f^{(i)}(n)\right) + \sum_{i=0}^{\cdt{f}{a}(n) - 1}\Tsucc(i)
+ \sum_{i=0}^{\cdt{f}{a}(n)}\Tleb\left(f^{(i)}(n), a\right) \\
& \hspace{5pt} + \runtime_{\li{nat_size}}(n - a) + \runtime_{\li{sub}}(n, a)
\end{aligned}\right)
\end{equation}
Where
\begin{itemize}
	\item $\Tleb(x, y)$ denotes the computation time of \li{x <=? y}.
	\item $\Tsucc(u)$ denotes the computation time of \li{N.succ(u)}.
	\item $\runtime_{\li{nat_size}}(n - a)$ denotes the computation time of \li{nat_size(n - a)}.
	\item $\runtime_{\li{sub}}(n, a)$ denotes the computation time of $n - a$.
\end{itemize}
Note that in the unary system, $\Tleb\left(f^{(i)}(n), a\right) = a + 1$ and $\Tsucc(i) = 1$, which accumulate into the summand $\Theta\big((a + 1)\cdt{f}{a}(n) \big)$ in \cref{lem: cdt-runtime}. In the binary system, we have
\begin{itemize}
	\item $\Tleb(x, y) = \Theta\left(1 + \log_2(\min\{x, y\})\right)$.
	\item $\Tsucc(u)$ is the number of consecutive least significant \li{1} bits of $u$.
\end{itemize}
Since $f^{(i)}(n)\ge a$ for $i < \cdt{f}{a}(n)$, the $\Tleb$ sum (third summand) on the RHS of \eqref{eq: cdt-bin-runtime-struct} is $\Theta\big((\log_2a + 1)\cdt{f}{a}(n)\big)$. The fourth and fifth summands are clearly $\Theta\left(\log_2n + 1\right)$ in total.
For the second summand, we will show that $\Tsucc(i)$ is amortized constant.
\begin{lem}
	For all $n\ge 1$, $S(n) = \displaystyle \sum_{i=0}^{n-1}\Tsucc(i) \le 2n + \log_2(n)$.
\end{lem}
\begin{proof}
	For $n = 1$, $\Tsucc(0) = 1$, our goal is $1\le 2$, which is trivial. For $n > 1$, observe that for all $k$, $\Tsucc(k) = \Tsucc\left(\frac{k-1}{2}\right) + 1$ if $k$ is odd and $1$ if $k$ is even. Thus for odd $n$, $S(n) = S(n-1) + 1$; for even $n$, i.e. $n = 2m$ for $m\ge 1$,
	\begin{equation*}
	\begin{aligned}
	S(n) & = \sum_{i=0}^{m}\Tsucc(2i) + \sum_{i=0}^{m-1}\Tsucc(2i+1)
	= \sum_{i=0}^{m}1 + \sum_{i=0}^{m-1}\left[\Tsucc(i) + 1\right] \\
	& = m+1 + S(m) + m = S(m) + n + 1
	\end{aligned}
	\end{equation*}
	From the above, it is easy to complete the proof via induction.
\end{proof}
The above analysis leads to the following result about countdown with binary numbers.
\begin{thm} \label{thm: cdt-runtime-bin}
	If $n$ is represented in binary, we have
	\begin{equation} \label{eq: cdt-runtime-bin}
	\runtime\big(\cdt{f}{a}\ , n\big) = \sum_{i=0}^{\cdt{f}{a}(n) - 1}
	\runtime\left(f, f^{(i)}(n)\right) + \Theta\big((\log_2a + 1)\cdt{f}{a}(n)\big) + \Theta\left(\log_2 n\right)
	\end{equation}
\end{thm}
%Substituting $a=1$ into \eqref{eq: cdt-runtime-bin} shows that \Cref{lem: inv-ack-hier-runtime} still holds.
%Similar to \Cref{sect: hard-code-lvl2}, the use of binaries is not immediately effective since the first level. We delve deeper into the hierarchy by \emph{hard-coding the $3^{\text{th}}$ level} and starts from there. Now
%\begin{equation*}
%\forall n, n+2  < n+3 < 2(n+2) \iff \forall n,
%\lfloor \log_2(n+2) \rfloor < \lceil \log_2(n+3) \rceil \le \lfloor \log_2(n+2) \rfloor + 1
%\end{equation*}
%This shift from floor to ceiling enables a direct computation, since $\lceil \log_2(n+3) \rceil$ can now be seen as the size of $(n+2)$'s binary representation.
%\begin{lstlisting}
%Definition alpha3 (n: N) : N := N.size (n+2) - 3.
%\end{lstlisting}
%Let $n\ge 2$. The computation of \li{N.size(n)} takes time equal to itself, so the above definition gives $\runtime(\alpha_3, n) \le 2\log_2n$. Fix an $i\ge 3$ and suppose $\runtime(\alpha_i, n) \le C_i\log_2n$. By \Cref{lem: inv-ack-hier-runtime},
\paragraph*{An inverse Ackermann computation in $\bigO\left(4^{\alpha(n)}\log_2 n\right)$ time}
Our new Coq definition is able to compute the correct countdown value, but only for strict binary contractions. Fortunately, the inverse hyperoperations $a\angle{n}b$ are all strict binary contractions when $a\ge 2$ starting from $n = 3$, so are the inverse Ackermann hierarchy $\alpha_n$ starting from $n = 2$. We can hard-code their few initial levels. We focus on the latter in this paper, but the former's definition can also be found in our Github repository.
\begin{lstlisting}
Fixpoint alpha (m : nat) (x : N) : N :=
  match m with
  | 0%nat => x - 1
  | 1%nat => x - 2
  | 2%nat => N.div2 (x - 2)
  | S m'  => countdown (alpha m') 1 (alpha m' x)
  end.
\end{lstlisting}
The first three levels are hard-coded, as we need to start the countdown from a binary strict contraction. Note that for all $x$,
\begin{equation*}
\left\lfloor \frac{x - 2}{2} \right\rfloor = \left\lceil \frac{x - 3}{2} \right\rceil \le \min\left\{x, \frac{x + 1}{2}\right\},
\end{equation*}
so the third level is correct and also a binary strict contraction above $1$. Next, we define the \emph{inverse Ackermann worker}.
\begin{lstlisting}
Fixpoint inv_ack_worker (f : N -> N) (n k : N) (bud : nat) : N :=
  match bud with
  | 0%nat  => k
  | S bud' => if n <=? k then k
              else let g := (countdown f 1) in
                   inv_ack_worker (compose g f) (g n) (N.succ k) bud'
  end.
\end{lstlisting}
Note that the above Coq Fixpoint is the direct translation of the \li{inv_ack_worker} on \li{nat}, with only the budget remaining \li{nat} as it is the decreasing argument. Now the inverse Ackermann function can be computed by the following Coq definition:
\begin{lstlisting}
Definition inv_ack (n : N) : N :=
  if (n <=? 1) then 0
  else if (n <=? 3) then 1
  else let f := (alpha 2) in inv_ack_worker f (f n) 2 (nat_size n).
\end{lstlisting}
Similar to the inverse Ackermann hierarchy, we hard code the result for $n = 0,1,2,3$. This ensures the correct output for small $n$, while for larger $n$ we can use \li{inv_ack_worker} with $\alpha_2$, which is the first binary strictly contractive level, as the starting function. Here the budget is \li{nat_size n}, or $\lfloor \log_2n \rfloor + 1$, which is enough for $n\ge 4$. The full proof of correctness can be found in our Github repository.

To analyze the time complexity of \li{inv_ack}, we decompose it into components, in a similar fashion to the derivation of \eqref{eq: inv-ack-runtime-improved}. We consider only $n\ge 4$.
\begin{equation*}
\runtime\left(\alpha, n\right) =
\left(\begin{aligned}
\sum_{k = 2}^{\alpha(n) - 1} \runtime\left(\cdt{\alpha_k}{1}, \alpha_k(n)\right) + \sum_{k = 2}^{\alpha(n)}\Tleb\left(\alpha_k(n), k\right) +
\sum_{k=2}^{\alpha(n) - 1}\Tsucc(k)\\
+ \runtime\left(\alpha_2, n\right) + \runtime_{\li{nat_size}}(n)
+ \Tleb(n, 1) + \Tleb(n, 3)
\end{aligned}\right)
\end{equation*}
In the above sum:
\begin{itemize}
	\item The last four summands amount up to $\Theta(\log_2n)$.
	\item The third summand is $\Theta(\alpha(n))$ since $\Tsucc$ takes amortized constant time.
	\item Each $\Tleb$ in the second summand is $\bigO\left(\log_2k\right)$, so the total sum is $\bigO\big(\alpha(n)\log_2\alpha(n)\big)$.
	\item In the first summand, for each $k$, $\runtime\left(\cdt{\alpha_k}{1}, \alpha_k(n)\right) = \runtime\left(\alpha_{k+1}, n\right) - \runtime\left(\alpha_k, n\right)$.
\end{itemize}
Therefore,
\begin{equation*}
\runtime\left(\alpha, n\right) =
\sum_{k = 2}^{\alpha(n) - 1} \big(\runtime\left(\alpha_{k+1}, n\right) - \runtime\left(\alpha_k, n\right)\big)
+ \Theta\left(\log_2 n\right) =
\runtime\left(\alpha_{\alpha(n)}, n\right) + \Theta\left(\log_2 n\right)
\end{equation*}
We bound the RHS by bounding $\runtime\left(\alpha_{\alpha(n)}(n)\right)$, and $\runtime\left(\alpha_i(n)\right)$ in general. Note that by $\alpha_2(n) = \left\lfloor \frac{n - 2}{2} \right\rfloor$, we have $\runtime(\alpha_2, n) \le 2\log_2 n$ for all $n$.

Suppose for $i\ge 2$ we already have $\runtime\left(\alpha_i(n)\right) \le C_i\log_2n$ for all $n$, and suppose all constants in asymptotic bounds in \cref{thm: cdt-runtime-bin} are $1$, by the fact $\alpha_{i+1} = \cdt{\alpha_i}{1} \circ \alpha_i$, we have
\begin{equation*}
\begin{aligned}
& \runtime\big(\alpha_{i+1}, n\big) =
\sum_{k=1}^{\alpha_{i+1}(n)} \runtime\left(\alpha_i, \alpha_i^{(k)}(n)\right)
+ \cdt{\alpha_i}{1}\big(\alpha_i(n)\big) + \runtime\left(\alpha_i, n\right) + \log_2 n
\\
& = \sum_{k=0}^{\alpha_{i+1}(n)} \runtime\left(\alpha_i, \alpha_i^{(k)}(n)\right) + \alpha_{i+1}(n) + \log_2 n \le C_i\sum_{k=0}^{\alpha_{i+1}(n)}\log_2 \left(\alpha_i^{(k)}(n)\right) + \alpha_{i+1}(n) + \log_2 n\\
 & \le C_i\log_2n + C_i\sum_{k=1}^{\alpha_{i+1}(n)}\alpha_i^{(k)}(n) + \alpha_{i+1}(n)
 + \log_2 n \le (4C_i+2)\log_2n,
\end{aligned}
\end{equation*}
where the last inequality follows from $\alpha_{i+1}(n)\le \log_2n$ and \Cref{lem: sum-alpha-repeat}.

Picking $C_i = 4^{i-1} - 1$ gives $C_2 > 2$ and $C_{i+1} > 4C_i + 2 \ \forall i$, so $\runtime\big(\alpha_i, n\big) \le C_i\log_2n \ \forall i\ge 3$ by induction. By \eqref{eq: inv-ack-runtime-improved}, for $n > 3 = \Ack(1, 1)$, $\runtime(\alpha, n) = \runtime\big(\alpha_{\alpha(n)}, n\big) = \bigO\big(4^{\alpha(n)}\log_2n\big)$. 

Note that this bound can potentially be improved by further tightening the above inequalities. Although we do not obtain an exact asymptotic runtime similar to \cref{thm: inv-ack-hier-runtime-improved}, since this bound of $4^{\alpha(n)}\log_2n$ is strictly larger than the lower bound of $\log_2n$, it is still extremely small and can be bounded by simpler expressions such as $(\log_2n)^2$.
%Our result is an improved version of the inverse Ackermann function which runs in time $\bigO\big(4^{\alpha(n)}\log_2n\big)$.
%\begin{equation*}
%\alpha(n) \triangleq \begin{cases}
%0 & \text{if } n\le 1\\ 1 & \text{if } 2\le n\le 3 \\ 2 & \text{if } 4\le n\le 7 \\
%\W\alpha\left(\alpha_3,
%\alpha_3(n), 3, n\right) & \text{if } n\ge 8
%\end{cases} \quad \text{ where } \alpha_3 \triangleq \lambda m. \big(\lfloor \log_2(m+2) \rfloor - 2\big)
%\end{equation*}
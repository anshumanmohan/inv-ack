% Aquinas' promise:
% We explain our core techniques of repeaters and countdowns that allow us to define each level of the Ackermann hierarchy—and their upper inverses—in a straightforward and uniform manner. We show how countdowns, in particular, can be written structurally recursively.

% Anshuman proposes:
% We introduce our core techniques of repeaters and countdowns. 
% We show how countdowns, in particular, can be written structurally recursively.

\iffalse
In this section we build the inverse Ackermann hierarchy, 
defining and proving the inverse relationship between 
this hierarchy and the Ackermann hierarchy.
\fi
% Hiding because this will now be in the next section.

\subsection{The repeater operation}

First, we develop a simple way to move 
from one level of the hyperoperation hierarchy to the
next. Addition is level 1, and $b$ repetitions of addition
give multiplication, which is level 2. Next, $b$ repetitions of 
multiplication give exponentiation, which is level 3. However, 
there is a subtlety here: in the former case, we add $a$ 
repeatedly to an \textit{initial value}, which must clearly be $0$. 
In the latter case, we multiply $a$ repeatedly to an initial value, 
which must now be $1$. In general, the formal definition for hyperoperation is
\begin{enumerate}
	\item \textit{Initial level:} $a[0]b = b + 1 \ \forall b$.
	\item \textit{Initial values:} $a[n+1]0 = a$ if $n = 0$, $0$ if $n = 1$, and $1$ otherwise.
	\item \textit{Recursive rule:} $ a[n+1]b = a[n]\left(a[n+1](b - 1)\right) \ \forall n \ \forall b \ge 1$
\end{enumerate}
The recursive formula may look complicated at first, but in fact is just \emph{repeated application} in disguise. By fixing $a$ and treating $a[n]b$ as a function of $b$, we can write
$$ \begin{aligned}
a[n+1]b & = a[n]\left(a[n+1](b-1)\right) = a[n]\left(a[n](a[n+1](b-2))\right) \\
 & =  \underbrace{\left( a[n]\circ a[n]\circ \cdots \circ a[n] \right)}_{b \text{ times}} \left(a[n+1]0\right) = \left(a[n]\right)^{(b)}\left(a[n+1]0\right)
\end{aligned} $$
where $f^{(k)}(u) \triangleq (f\circ f\circ \cdots \circ f)(u)$ denotes applying a function $f$ to an input $u$ $k$ times. In order to view the relationship between the $(\text{n+1})^{\text{th}}$- and $(\text{n})^{\text{th}}$-levels in a \emph{functional} way, we need an operation that transforms the latter to the former, which leads us to the notion of \emph{repeater}.
\begin{defn}
For all $a\in \mathbb{N}$ and $f: \mathbb{N}\to \mathbb{N}$, the \emph{repeater from} $a$ of $f$, denoted by $\rf{f}{a}$ , is a function $\mathbb{N}\to \mathbb{N}$ such that $\rf{f}{a}(n) = f^{(n)}(a) \ \forall n$.
\end{defn}
The Gallina definition is modified to structurally decrease on $n$:
\begin{lstlisting}
Fixpoint repeater_from (a:nat) (f:nat->nat) (n:nat)
:= match n with
   | 0 => a
   | S n' => f (repeater_from a f n')
end. 
\end{lstlisting}
The notation $\rf{f}{a}(b)$ does much better at separating the function, i.e. the repeater of $f$, and the variable $n$ than $f^{(n)}(a)$, while making clear that $a$ is a parameter of \emph{repeater} itself. It allows a simple and function-oriented definition of hyperoperations:
\begin{equation}
a[n]b = \begin{cases}
b + 1 & \hspace{-10pt}\text{ if } n = 0 \\
\rf{a[n-1]}{a_n}(b) & \hspace{-10pt}\text{ if } n \ge 1
\end{cases}
\ \ \text{ where } \ a_n = \begin{cases}
a & \hspace{-10pt}\text{ if } n = 1 \\
0 & \hspace{-10pt}\text{ if } n = 2 \\
1 & \hspace{-10pt}\text{ if } n \ge 3
\end{cases}
\end{equation}

\subsection{Increasing expansions and their inverse}

Our goal is to find an inverse hierarchy to the hyperoperations, which should include division, logarithm and $\log^*$ as inverses to multiplication, exponentiation and tetration. The advent of repeater motivates an ``inverse repeater'' operation that takes us to the next level in the supposed ``inverse hyperoperation'' hierarchy. Before going into details, let us clarify the notion of ``inverse''.
\begin{defn} \label{defn: inverse}
	For all $F:\mathbb{N}\to \mathbb{N}$, $f:\mathbb{N}\to \mathbb{N}$ is the \emph{upper inverse} of $F$ if $f(n) = \min\{m : F(m)\ge n\} \ \forall n$, and is the \emph{lower inverse} of $F$ if $f(n) = \max\{m : F(m)\le n\} \ \forall n$.
\end{defn}
To construct a useful notion of inverse for our purpose, observe that for $a\ge 2$, each $a[n]$ is strictly increasing and grows to infinity with its input, while not always reaches $0$, which ensures the existence of the upper but not the lower inverse, since $\{m : a[n]m \le 0 \} = \varnothing$ for $n\ge 3$. Thus we decide to go on with the upper inverse notion, and leave the other for discussion in \cref{sec: discussion}. Furthermore, we can restrict ourselves to only considering strictly increasing $F$, which in fact gives more sense to the above definition since inverse preserves increasing-ness, and allows us to describe upper inverse in a simple logical sentence:
\begin{thm} \label{thm: upp-inverse-rel}
	If $F:\mathbb{N}\to \mathbb{N}$ is increasing, then $f$ is the upper inverse of $F$ if and only if $\ \forall n, m : f(n)\le m \iff n \le F(m)$.
\end{thm}
\begin{proof}
Fix $n$, the sentence $n\le F(m) \iff f(n)\le m \ \forall m$ implies: (1) $f(n)$ is lower bound to the set $\{m: F(m)\ge n \}$ and (2) $f(n)$ is in the set itself since plugging in $m := f(n)$ will yield $n\le F(f(n))$, which makes $f$ the upper inverse of $F$. Conversely, if $f$ is the upper inverse of $F$, we immediately have $n\le F(m)\implies f(n)\le m \ \forall m$. Now for all $m \ge f(n)$, $F(m)\ge F(f(n)) \ge n$ by increasing-ness, thus complete the proof.
\end{proof}
The last property we would like $F$ to have is one that ensures strict increasing-ness can be preserved through \emph{repeater}. Suppose for some $a$ and strictly increasing $F$, the function $\rf{F}{a}\ $ is strictly increasing, then the chain $a$, $F(a)$, $F^{(2)}(a)$, \ldots has to be strictly increasing, which leads to the notion of \emph{expansions}.
\begin{defn}
Given $a\in \mathbb{N}$, a function $F:\mathbb{N}\to\mathbb{N}$ is an \emph{expansion from} $a$ if $F(n)\ge n+1 \ \forall n\ge a$.
\end{defn}
Conveniently, if $a\ge 1$ and $F$ is an expansion from $a$, $\rf{F}{a}(n) = F^{(n)}(a) \ge a + n \ge 1 + n$ $\forall n$, so $\rf{F}{a}\ $ is itself an expansion from $0$. Combined with the preservation of strict increasing-ness through repeater, we can collectively define strictly increasing expansions on $\mathbb{N}$ to be \emph{repeatable} from any $a\ge 1$, with repeatability being preserved through \emph{repeater} from $a$. In the next section, we show how repeatable functions' upper inverses can be constructed in a systematic way that allow us to build inverses for the hyperoperation hierarchy.

\subsection{Contractions and the countdown operation}

This is the final step leading to the inverse hypeoperations, where we develop a way to climb from the one inverse level to the next. Suppose $f$ is the upper inverse of a repeatable (i.e. strictly increasing expansion) $F$, then for $a\ge 1$, $\rf{F}{a}\ $ is repeatable and has an upper inverse $f^*$. Now $\forall n, m$,
$$\begin{aligned}
 f^*(n)\le m & \iff n\le \rf{F}{a}(m) = F^{(m)}(a) \iff f(n)\le F^{(m-1)}(a) \\
 & \iff f^{(2)}(n)\le F^{(m-2)}(a) \iff \ldots \iff f^{(m)}(n)\le a
\end{aligned} $$
This implies $f^*(n)$ is the minimum number of times $f$ needs to be repeated over $n$ to yield a result below $a$. Before we can define $f^*(n)$ to be the minimum of $\{m: f^{(m)}\le a \}$ and claim success, we need to make sure: (1) that set is non-empty, so that it has a minimum, and (2) we can reliably find that minimum within finitely many steps. The most ideal situation would be that the chain $n$, $f(n)$, $f^{(2)}(n)$, \ldots decreases strictly until reaching $a$, which leads to the notion of \emph{contractions}.
\begin{defn} \label{defn: contracting}
A function $f : \mathbb{N} \to \mathbb{N}$ is a \textit{contraction} if $f(n) \le n \ \forall n\in \mathbb{N}$. Given an $a \ge 1$, a contraction $f$ is \textit{strict from} $a$ if $n\ge f(n)+1 \ \forall n\ge a$. We further denote by $\contract$ the set of contractions and $\contract_a$ the set of contractions strict from $a$.
\end{defn}
That leaves the question: what type of functions $F$ whose inverses are contractions? Wonderfully, we already have an answer:
\begin{thm}
If $F$ is a strictly increasing expansion from $a$, the upper inverse $f$ of $F$ is (non-strictly) increasing contraction,  from $a$.
\end{thm}

\begin{defn} \label{defn: countdown}
Given a contraction that is strict from some $a$, 
the \textit{countdown\_to} operation on $f$, 
written $\cdt{f}{a}(n)$, is the number of times
that $f$ can be compositionally applied to $n$
without the result going below $a$. 

\begin{equation} \label{eq: countdown}
\cdt{f}{a}( n ) \triangleq (\textit{blah, but much simplified})
\end{equation}
\end{defn}

Repeater can be written in Coq without much trouble, but Countdown
proves a little more challenging. The definition above is a somewhat
simplified version of the version in our development, which we shall
discuss briefly here. 

{\color{red}(listing of final code of countdown\_to\_worker)}

Essentially, we introduce the notion of a \textit{budget}, which is 
the maximum number of times we will try to compositionally 
apply $f$ on the input. If a certain number of compositional applications 
of $f$ makes the input go below $a$, \emph{i.e.} $f^{k}(n) < a$, 
we return $k$, the number of applications it took. If we exhaust the 
budget and have still not gone below $a$, 
we fail by returning the budget itself.

This defnition is somewhat clunky, but it can clearly be written
structurally recursively in Coq, with the budget as the decreasing
argument. Further, it should be clear to see that 
if we provide the worker with a budget of $n$ and also ensure that the 
function $f$ is a contraction that is strict from $a$, we will 
never run out of budget, and the return value will truly be the 
number of times $f$ was applied. In our proofs, we always use 
\textit{countdown\_to\_worker} with these two conditions satisfied, 
\emph{i.e.}

{\color{red}(code of countdown\_to and countdownable\_to)


% Hiding because I'm trying to refine this into a simpler version above.
\iffalse
The important observation is that, if the sequence 
$\{n, f(n), f(f(n)), \ldots\}$ strictly decreases to 
$0$, then $f^*$ counts the minimum index where it reaches 
$1$ or below. We give a formal definition for functions 
with such decreasing sequences:}

\begin{defn} \label{defn: contraction}
A function $f: \mathbb{N} \to \mathbb{N}$ is a \textit{contraction} if $f(0) = 0$ and $f(n) \le n-1 \ \forall n > 0$.
\end{defn}

\begin{thm} \label{thm: countdown contraction}
If $f: \mathbb{N} \to \mathbb{N}$ is a contraction, then
\begin{equation*}
A = \left\{k: f^{(k)}(n) \le 1\right\} \neq \varnothing \ \text{ and } \ f^*(n) = \min A
\end{equation*}
In other words,
\begin{equation*}
\forall n, k\in \mathbb{N}, \ f^*(n) \le k \iff f^{(k)}(n) \le 1
\end{equation*}
\end{thm}

\begin{proof}[Proof sketch]
By \eqref{eq: countdown} and \cref{defn: contraction}, we have
\begin{equation*}
f^*(n) = \begin{cases}
0 & \text{ if } n \le 1 \\ 1 + f^*(f(n)) & \text{ if } n > 1
\end{cases}
\end{equation*}
Then by a strong induction on $n$, the theorem holds.
\end{proof}
\fi
% ...end of hide 
% iding because I'm trying to refine this into a simpler version above.

% Hiding because Linh is going to incorporate this into the next section.
\iffalse 
\subsection{The inverse Ackermann hierarchy}

With the above countdown operation in hand, we can 
build the inverse Ackermann hierarchy.

\begin{defn} \label{defn: inv_ack_hier}
The inverse Ackermann hierarchy is a sequence of 
functions $\alpha_0, \alpha_1, \ldots $ recursively defined as:
\begin{enumerate}
	\item $\alpha_0(n) = \max\{n-2, 0\} \ \ \ \forall n \in \mathbb{N}$.
	\item $\alpha_m = \alpha_{m-1}^*  \ \ \ \forall m\in \mathbb{N}_{>0}$.
\end{enumerate}
\end{defn}

We will prove that each function $\alpha_m$ is a contraction, 
thus the $*$ operations are truly counting down to $1$.

\begin{thm} \label{thm: inv_ack_countdown}
For all $m\in\mathbb{N}$, $\alpha_m$ is a contraction and
\begin{equation}
\alpha_{m+1}(n) = \min\left\{ k : \alpha_m^{(k)}(n) \le 1 \right\}
\end{equation}
\end{thm}

\begin{proof}
TODO TODO TODO
\end{proof}

Having sufficiently established the inverse Ackermann 
hierarchy, we now link it to the Ackermann hierarchy 
in \cref{defn: ack_hier}. However, the relationship is 
not trivially clear, as the Peter-Ackermann function is 
in fact not exactly {\color{magenta}their inverses.} 
We first define a \textit{canonical} variant of the 
Ackermann hierarchy, then use it as an intermediate to 
link first two hierarchies.

\subsection{The canonical Ackermann hierarchy}

The canonical Ackermann hierarchy is a somewhat ``cleaner'' 
variant of the Ackermann hierarchy, with simpler initial 
values, but still built on the repeated application operation.

\begin{defn} \label{defn: rep_app}
For any function $F: \mathbb{N} \to \mathbb{N}$, the 
\textit{repeater} of $F$ is another function $F^R : 
\mathbb{N} \to \mathbb{N}$ defined by:
\begin{equation}
F^R(n) = \begin{cases}
1 & \text{ if } n = 0 \\ F\left(F^R(n - 1)\right) & \text{ if } n \ge 1
\end{cases}
\end{equation}
In other words, $\forall n, F^R(n) = F^{(n)}\left(F^R(0)\right) = F^{(n)}(1) \ \ $.
\end{defn}

Formally defining the repeated application operation 
helps us define the canonical Ackermann hierarchy in 
a neat way below.

\begin{defn} \label{defn: can_ack_hier}
The canonical Ackermann hierarchy is a sequence of 
functions $\text{C}_0, \text{C}_1, \ldots $ defined as:
\begin{enumerate}
	\item $\CA_0(n) = n + 2 \ \ \ \forall n\in \mathbb{N}$.
	\item $\CA_m = \CA_{m-1}^R \ \ \forall m\in \mathbb{N}_{>0}$.
\end{enumerate}
\end{defn}

Firstly, we explore the relationship between $C_m$ and 
$\alpha_m$. We use the following theorem:

\begin{thm} \label{thm: inv_ack_can_ack}
For all $m, n \in \mathbb{N}$, we have:
\begin{equation} \label{eq: inv_ack_can_ack}
\forall N \in \mathbb{N}: \alpha_m(N) \le n \iff N \le \CA_m(n)
\end{equation}
In other words
\begin{equation} \label{eq: inv_ack_can_ack_0}
\CA_m(n) = \max\left\{N : \alpha_m(N) \le n\right\}
\end{equation}
\end{thm}

Before proving this theorem, we will need to prove each 
function in the inverse and canonical Ackermann hierarchy 
is increasing (non-strictly). Then \eqref{eq: inv_ack_can_ack} 
is sufficient to explain the ``inverse'' relationship between them.

%\begin{lem} \label{lem: inv_ack_hier_incr}
%For all contraction $f$, if $f$ is increasing then so is $f^*$.
%\end{lem}
%
%\begin{proof}
%
%\end{proof}
%
%\begin{lem}
%For all function $F: \mathbb{N}\to \mathbb{N}$, if $F$ is increasing then so is $F^R$.
%\end{lem}
%
%\begin{proof}
%TODO TODO TODO
%\end{proof}

\begin{lem}  \label{lem: countdown_rep_app}
For any function $f, F: \mathbb{N} \to \mathbb{N}$, 
if $f$ is a contraction and $\forall n, N\in \mathbb{N}$, 
$f(N) \le n \iff N \le F(n)$, then
$$ \forall n, N\in \mathbb{N}, N\le f^*(n) \iff N \le F^R(n) $$
\end{lem}

\begin{proof}
By \Cref{thm: countdown contraction} and \Cref{defn: rep_app}, we have:
$\displaystyle f^*(N)\le n \iff f^{(n)}(N) \le 1 \iff N \le F^{(n)}(1) = F^R(n) $
\end{proof}

Now we can proceed with the proof for \Cref{thm: inv_ack_can_ack}

\begin{proof}[Proof of \Cref{thm: inv_ack_can_ack}]
We prove by induction on $m$. The base case is the following statement:
$$ \forall n, N\in \mathbb{N}, \ N - 2\le n \iff N \le n + 2 $$
, which is trivial. The inductive step follows directly from \Cref{lem: countdown_rep_app}.
\end{proof}

Now that we have established our canonical Ackermann hierarchy 
and its relation with the inverse Ackermann hierarchy, let us 
connect it to the original Ackermann hierarchy to complete the link.

\begin{thm} \label{thm: can_ack_ack}
For all $m, n\in \mathbb{N}$, we have $\CA_m(n+2) = \Ack_{m+1}(n) + 2$.
\end{thm}

\begin{proof} TODO TODO TODO.
%An induction on $m$ will suffice. The base case is the following:
%$$ \forall n\in \mathbb{N}, \ (n + 2) + 2 = \Ack_1(n) + 2 $$
%, which is trivial. For the inductive step, suppose $m\ge 1$ and
%$\displaystyle \forall n\in \mathbb{N}, \CA_{m-1}(n+2) = \Ack_m(n) + 2 $.
%
%We need to prove the statement $P(n) := \CA_m(n+2) = \Ack_{m+1}(n) + 2$ holds for all $n\in \mathbb{N}$. Again, we use induction on $n$.
%
%For $n = 0$, $P(0) := \CA_m(2) = \Ack_{m+1}(0) + 2$, or $\CA_{m-1}(\CA_{m-1}(1)) = \Ack_m(1) + 2$.
\end{proof}

\subsection{Linking it all together}

To conclude this section, we link everything together by 
stating and proving the main theorem that connects the 
inverse Ackermann hierarchy and the Ackermann hierarchy. 
We then use this theorem to state and prove a relation 
between the inverse Ackermann hierarchy and the inverse 
Ackermann function.

\begin{thm}  \label{thm: inv_ack_ack}
For all $m, n, k \in \mathbb{N}$, we have:
\begin{equation}
n \le \Ack(m, k) \iff \begin{cases}
n \le k + 1 & \text{ if } m = 0 \\ \alpha_{m-1}(n+2) \le k + 2 & \text{ if } m > 0
\end{cases}
\end{equation}
\end{thm}


\begin{proof}
TODO TODO TODO
\end{proof}

The next theorem is a corollary of the above, which lays the 
theoretical groundwork for us to compute the inverse Ackermann 
function in linear time.

\begin{thm}
For all $n\mathbb{N}$, we have:
\begin{equation}
\alpha(n) = \begin{cases}
0 & \text{ if } n \le 1 \\
1 + \min\left\{ m: \alpha_m(n+2) \le m + 3 \right\} & \text{ if } n \ge 2
\end{cases}
\end{equation}
\end{thm}

\begin{proof}
TODO TODO TODO
\end{proof}

In the next section, we will devise an algorithm to compute each 
of the functions in the inverse Ackermann hierarchy in linear time, 
and an algorithm to compute the inverse Ackermann function in linear time.

\fi